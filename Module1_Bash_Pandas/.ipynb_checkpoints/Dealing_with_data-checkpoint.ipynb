{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubingLi123/foster_2023spring/blob/2023sp-master/Module1_Bash_Pandas/Dealing_with_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7hZ_P551UjMB"
      },
      "outputs": [],
      "source": [
        "#If opening in colab run this cell\n",
        "!git clone https://github.com/RubingLi123/foster_2023spring.git\n",
        "%cd foster_2023spring/Module0_Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usrd5IerUjMX"
      },
      "source": [
        "# Python and Pandas Data Frames\n",
        "\n",
        "\n",
        "Spring 2023 - Instructors: Foster Provost and Rubing Li\n",
        "\n",
        "Teaching Assistant: Rubing Li\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIXpcJR6UjMa"
      },
      "source": [
        "## Python Packages and Built-in Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BtnrGyFUjMe"
      },
      "source": [
        "Python has a ton of packages that make doing complicated stuff very easy. We won't discuss how to install packages, or give a detailed list of what packages exist, but we will give a brief description about how they are used. \n",
        "\n",
        "An easy way to think of why package are useful is by thinking: \"**Python packages give us access to MANY functions**\".\n",
        "\n",
        "Packages contain pre-defined functions (built-in) that make our life easier!  We've seen pre-defined functions before, for example, the function 'str()' that we used to convert numbers into strings in the Python Basics notebook.\n",
        "\n",
        "In this class we will use five packages frequently: `pandas`, `sklearn`, `matplotlib`,  `seaborn`, and `numpy`:\n",
        "\n",
        "- **`pandas`** is a data manipulation package. It lets us store data in a data frame--which is the basic data structure used in data analytics. More on this soon.\n",
        "- **`sklearn`** is a machine learning and data science package. It lets us do fairly complicated machine learning tasks, such as building regression or probability estimation models with only a few lines of code. (Nice!)\n",
        "- **`matplotlib`** is a data visualization package.  It lets you make plots and graphs directly from your code. This can be a secret weapon when combined with notebooks, as you can very easily rerun analyses on different data or with slightly different code, and the graphs can just appear magically.  (Ok, always easier said than done, but you get the idea.)\n",
        "- **`seaborn`** is an extension to matplotlib that helps make your plots look more appealing.\n",
        "- **`numpy`** (pronounced num-pie) is used for doing \"math stuff\", such as complex mathematical operations (e.g., square roots, exponents, logs), operations on matrices, and more. \n",
        "\n",
        "As we use these through the semester, their usefulness will become increasingly apparent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is5RUrTdUjMi"
      },
      "source": [
        "To make the contents of a package available, you need to **import** it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MjLdWQ_cUjMk"
      },
      "outputs": [],
      "source": [
        "# load entire package\n",
        "import pandas\n",
        "import sklearn\n",
        "import matplotlib\n",
        "import numpy\n",
        "import seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV9YPDLGUjMu"
      },
      "source": [
        "Sometimes it is easier to use short names for packages. This has become the norm now, so let's do it so that you recognize it if you encounter it in your work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hlvpxc2mUjMx"
      },
      "outputs": [],
      "source": [
        "# Load package and assign to shorter variable name\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# this trick is required to get plots to display inline with the rest of your notebook,\n",
        "# not in a separate window\n",
        "%matplotlib inline\n",
        "\n",
        "# just some stylistic tweaks for seaborn\n",
        "sns.set(style='ticks', palette='Set2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bXfdvvrUjM7"
      },
      "source": [
        "We can now use package-specific things. For example, numpy has a function called `sqrt()` which will give us the square root of a numpy number. Since it is part of numpy, we need to tell Python that that's where it is by using a dot (e.g., `np.sqrt()`).\n",
        "\n",
        "In the following cell you can also see how to write **comments** in your code. Take my advice: **Write comments as you go**.  It's helpful when you want to collaborate, then you don't have to figure out what you did to explain it to your collaborator.  But even more: often you need to come back to **your own** analysis weeks, months, or even years later, and you will thank yourself for explaining what you did!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3DFEJWAZUjNI"
      },
      "outputs": [],
      "source": [
        "# First I'll just set up some very simple data structures for what follows\n",
        "some_list = [0,0,1,2,3,3,4.5,7.6]\n",
        "print(some_list)\n",
        "some_dictionary = {'student1': '(929)-000-0000', 'student2': '(917)-000-0000', 'student3': '(470)-000-0000'}\n",
        "print(some_dictionary)\n",
        "some_set = set( [1,2,4,4,5,5] )\n",
        "print(some_set)\n",
        "\n",
        "\n",
        "# In this part of the code I am demonstrating using numpy (np) functions\n",
        "print (\"Square root: \" + str ( np.sqrt(25) ))\n",
        "print (\"Maximum element of our previous list: \" + str( np.max(some_list) ))\n",
        "\n",
        "# In this part of the code I am using \"regular\" python functions\n",
        "print (\"Number of elements in our previous list: \" + str( len(some_list) ))\n",
        "print (\"Sum of elements in our previous list: \" + str( sum(some_list) ))\n",
        "print (\"Range of 5 numbers (remember we start with 0): \" + str( range(5) ))\n",
        "\n",
        "# #Bonus LIST COMPREHENSIONS (google it!)\n",
        "# some_list_squared = [i*i for i in some_list]\n",
        "# #This is the same as:\n",
        "# some_list_squared_too = []\n",
        "# for i in some_list:\n",
        "#     some_list_squared_too.append(i*i)\n",
        "\n",
        "# print(f\"some_list_squared: {some_list_squared} = some_list_squared_too:{some_list_squared_too}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzDyXE8FUjNW"
      },
      "source": [
        "What about the package **Pandas**? \n",
        "\n",
        "Pandas gives us the **DATAFRAME** -- one of the main data structures used in data analytics.\n",
        "\n",
        "A Dataframe is 2-dimensional data structure with columns of potentially different types, along with column and row labels. It is generally the most commonly used pandas object. Along with the data, you can optionally pass index (row labels) and columns (column labels) arguments. It's often convenient to think of it as a spreadsheet with super powers! [More details here](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe)\n",
        "\n",
        "Pandas data frames can be constructed from most common data sources a data scientist will encounter: csv files, excel spreadsheets, sql databases, json, url pointers to other data sources, and even from other data already stored in one's python code. \n",
        "\n",
        "Let's take a look at **creating** a data frame from a common \"toy\" dataset presenting automobile mpg information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Cldu7Rx2UjNY"
      },
      "outputs": [],
      "source": [
        "# This reads the data from a url and sets the column names.\n",
        "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data-original\"\n",
        "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model', 'origin', 'car_name']\n",
        "mpg_df = pd.read_csv(url, delim_whitespace=True, header=None, names=column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZN5QV4nUjNi"
      },
      "source": [
        "We now have the data loaded in a pandas data frame, as a starter, let's see some of the (MANY!) ways pandas makes it convenient to explore a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UT1XYkS3UjNk"
      },
      "outputs": [],
      "source": [
        "# First, just get a peek at the data:\n",
        "mpg_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lsRoaZNZUjNt"
      },
      "outputs": [],
      "source": [
        "# Some general stats about the data\n",
        "mpg_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gSeLF6e1UjN1"
      },
      "outputs": [],
      "source": [
        "# Info about the rows and columns themselves\n",
        "mpg_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHE8dNDwUjN_"
      },
      "outputs": [],
      "source": [
        "# How many of each type of engine? \n",
        "mpg_df[\"cylinders\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Jnhx0F6mUjOH"
      },
      "outputs": [],
      "source": [
        "# Total horsepower\n",
        "mpg_df[\"horsepower\"].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3AP4qIuvUjOO"
      },
      "outputs": [],
      "source": [
        "# Average horsepower per engine type\n",
        "mpg_df.groupby(\"cylinders\").horsepower.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6RptfbVLUjOV"
      },
      "outputs": [],
      "source": [
        "# Plot a histogram of mpg\n",
        "mpg_df.hist(\"mpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "u1mYhbsXUjOe"
      },
      "outputs": [],
      "source": [
        "# Or a scatter plot of acceleration vs mpg\n",
        "mpg_df.plot(kind=\"scatter\", x=\"acceleration\", y=\"mpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IHXNULs7UjOk"
      },
      "outputs": [],
      "source": [
        "# Some pretty plotting comparing weight to mpg and adding a regression line in seaborn\n",
        "sns.jointplot(\"weight\", \"mpg\", mpg_df, kind=\"reg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y9QEGpxUjOs"
      },
      "source": [
        "Pandas is widely used and has a very active development community contributing new features. If there is some kind of analysis you want to do on your data, chances are, it already exists. The [documentation for the pandas library](https://pandas.pydata.org/pandas-docs/stable/) is very good, but the site's search functionality is, unfortunately, poor. Google is often better to find the information you need.\n",
        "\n",
        "One important component of pandas is indexing and selecting components of the data. This is a extremely rich topic, so we'll only touch on it here. Please [consult the documentation](https://pandas.pydata.org/pandas-docs/stable/indexing.html) for more info. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1TerOKbXUjOt"
      },
      "outputs": [],
      "source": [
        "# Columns can be selected using the `[]` operator, which accepts one column name or a list of several\n",
        "mpg_df[[\"cylinders\", \"car_name\"]].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pcBGAzwVUjO0"
      },
      "outputs": [],
      "source": [
        "# As some \"syntactic sugar\", pandas also allows selection using the `.column_name` notation\n",
        "mpg_df.car_name.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "s3Is0PiHUjO7"
      },
      "outputs": [],
      "source": [
        "# Note that this can also be used for assignment of values!\n",
        "original_names = mpg_df.car_name.copy()\n",
        "mpg_df.car_name = original_names + \" Test!\"\n",
        "print(mpg_df.car_name.head())\n",
        "mpg_df.car_name = original_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RWvSo3sUjPB"
      },
      "source": [
        "For selecting rows from the data there are two options:\n",
        "- `.loc`: for selecting rows based on the _row label_\n",
        "- `.iloc`: for selecting rows based on the _row number_\n",
        "\n",
        "In the prior example, the row label and the row number are the same; often one wants to assign a label (a unique id) to each rows. In many cases, this would be something like a date or a user id. Note: these two selectors can also be used to pick columns, but that's a bit less common. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XzPdOL9XUjPD"
      },
      "outputs": [],
      "source": [
        "# Returns row #5 -- the 6th row.  NB: it returns one row as a column!\n",
        "mpg_df.iloc[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p-bL9Ls8UjPK"
      },
      "outputs": [],
      "source": [
        "# Returns the first 6 rows\n",
        "mpg_df.iloc[:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcPQal5WUjPO"
      },
      "source": [
        "If we have _actual labels_ as an index for a dataframe, we can use `.loc` to select using values from that index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iuGMVYtfUjPR"
      },
      "outputs": [],
      "source": [
        "#Let's set the row label (index) to be the car name.  Note: these are not unique.\n",
        "car_index_df = mpg_df.set_index(\"car_name\", inplace=False)\n",
        "#Now, let's see what we have for a couple car names\n",
        "car_index_df.loc[[\"amc rebel sst\", \"plymouth fury iii\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kFTLJgsUjPX"
      },
      "source": [
        "One can also select those rows that match a particular condition. Say I want to only see those rows that have an acceleration less that 10 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LrgE1B5zUjPZ"
      },
      "outputs": [],
      "source": [
        "mpg_df[mpg_df.acceleration < 10]  #some of the classic muscle cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJehQKivUjPf"
      },
      "source": [
        "Often, one wants to create a data frame from information that is available \"in code\"- these might be results of prior computations that aren't already in pandas or maybe just some small static dataframe that stores some info. There are two common ways to do this: (1) lists-of-lists with an additional list of column names and (2) lists of dictionaries. I prefer the latter since the data in this case is self-descriptive, order isn't important, and missing data is handled more smoothly, but I'll give examples below for both. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ALoIIuK7UjPh"
      },
      "outputs": [],
      "source": [
        "# List-of-lists approach\n",
        "\n",
        "list1 = ['studentA',22,'(929)-000-000']\n",
        "list2 = ['studentB',np.nan,'(646)-000-000']\n",
        "list3 = ['studentC',30,'(917)-000-000']\n",
        "list4 = ['studentD',31,'(646)-001-001']\n",
        "list5 = ['studentE',np.nan,'(929)-001-001']\n",
        "list6 = ['studentF',30,'(917)-001-001']\n",
        "list7 = ['studentG',30,'(470)-001-001']\n",
        "\n",
        "list_of_lists = [list1, list2, list3, list4, list5, list6, list7]\n",
        "column_names = ['Name','Age','Mobile']\n",
        "\n",
        "lol_df = pd.DataFrame(list_of_lists,columns=column_names)\n",
        "lol_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Bq-96gI8UjPn"
      },
      "outputs": [],
      "source": [
        "# This is the list of dicts approach\n",
        "alice = {\"name\": \"alice\", \"age\": 25, \"mobile\":\"555-222-9000\"}\n",
        "bob = {\"name\": \"bob\", \"age\": 100}\n",
        "casey = {\"age\":35, \"name\": \"casey\", \"mobile\":\"1-877-kars-4kids\"}\n",
        "\n",
        "list_of_dicts = [alice, bob, casey]\n",
        "lod_df = pd.DataFrame(list_of_dicts)\n",
        "lod_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1EAn_pYUjPr"
      },
      "source": [
        "We can also add columns (they should have the same number of rows as the dataframe they are being added to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QVaBptecUjPu"
      },
      "outputs": [],
      "source": [
        "lol_df['Business Major'] = ['yes','no','yes','yes','yes','no','yes']\n",
        "lol_df['Years Experience'] = [1,4,2,6,0,3,0]\n",
        "lol_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19VB4XNyUjP1"
      },
      "source": [
        "\n",
        "What about operations on entire columns? This can make data munging much easier!  \n",
        "\n",
        "*For example, when preparing data for predictive modeling (machine learning) we do \"feature engineering\" -- creating new variables that we believe/hope will be predictive of some target.  We usually want to engineer the same new variables for every data instance (they'll have different values for different instances, in order to be useful).*\n",
        "\n",
        "Let's take the difference between age and years of experience:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KGbWioxNUjP2"
      },
      "outputs": [],
      "source": [
        "lol_df[\"Age\"] - lol_df[\"Years Experience\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Erzc4VUjP9"
      },
      "source": [
        "All of the data frames used thus far have had missing values. We see that by default, pandas just displays `NaN`, when the value of a cell is unknown. Sometimes this interferes with the computation we're trying to accomplish. Fortunately, there is a [suite of functionality](https://pandas.pydata.org/pandas-docs/stable/missing_data.html) for dealing with missing data built in.\n",
        "\n",
        "Let's (for some reason) fill missing age info with the average age when doing our dataframe difference computation.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8Pr2VhKKUjP_"
      },
      "outputs": [],
      "source": [
        "lol_df[\"Age\"].fillna(lol_df[\"Age\"].mean()) - lol_df[\"Years Experience\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBS8l4BGUjQE"
      },
      "source": [
        "#### Extra added bonus!!   ---  Auto-complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s3UnfQuUjQG"
      },
      "source": [
        "One of the most useful things about an IPython notebook is its functionality for helping us to figure out Python details. \n",
        "\n",
        "Try this: type `mpg_df.hist` in the cell below and press `control-space'.  (Recall that we used this function above.)  \n",
        "\n",
        "Now try it with mpg_df.hist(\n",
        "\n",
        "Now try it with just mpg_df.h\n",
        "\n",
        "[NB: some documentation says on a mac to use command-space, but ctrl-space is what works for me.]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mpg_df.hist"
      ],
      "metadata": {
        "id": "4NYYQGOTdKpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mpg_df.hist("
      ],
      "metadata": {
        "id": "lB3Oypy3eRsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_VRFtj2bUjQP"
      },
      "outputs": [],
      "source": [
        "mpg_df.h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fY1gFduUjQU"
      },
      "source": [
        "That last one is super useful when (like me) you forget the names of everything!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaY8lEYGUjQX"
      },
      "source": [
        "#### Special Bonus 2! -- inline python help\n",
        "Another way to get access to the documentation of the objects and functions you're interacting with inside the notebook is just to put a `?` at the beginning of the line, followed immediately by the thing you'd like help on:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Vu3jFgxOUjQY"
      },
      "outputs": [],
      "source": [
        "?np.sqrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Mww4bKiiUjQd"
      },
      "outputs": [],
      "source": [
        "?float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yySSdNGKUjQi"
      },
      "source": [
        "# A Taste of Whats to Come: Predictive Modeling\n",
        "We've seen thus far some examples of how jupyter, pandas and some other tools are great for manipulating and exploring data. This is great, but much of the power of data comes from its ability to help us predict/estimate unknown quantities. While this topic will be explored in much greater depth throughout the remainder of this course, let's take a sneak peek into some of what we'll be doing in the future. \n",
        "\n",
        "For this, let's build a simple model to predict the mpg of cars from the other information we have available on those cars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mFXeoOydUjQk"
      },
      "outputs": [],
      "source": [
        "# First we'll need to import the predictive model class that we'll use\n",
        "from sklearn import linear_model \n",
        "\n",
        "# Now, choose a particular kind of linear regression model\n",
        "# Get set up to \"train\" one of those (learn it from data)\n",
        "my_linear_model = linear_model.Lasso(alpha=0.01)\n",
        "\n",
        "# Assemble the training data (we will define all this nomenclature in the next few classes)\n",
        "# Let's use these columns as features and the target variable\n",
        "features = [\"weight\", \"acceleration\", \"cylinders\", \"displacement\"]\n",
        "target = \"mpg\"\n",
        "\n",
        "# Eliminate (drop) any instances with missing values (NaNs) for now\n",
        "cleaned_df = mpg_df.dropna()\n",
        "\n",
        "# Train the model you set up on the data\n",
        "#   a.k.a. Fit the model to the data!\n",
        "my_linear_model.fit(cleaned_df[features], cleaned_df[target])\n",
        "\n",
        "# Show the coefficients of the linear model\n",
        "pd.DataFrame([dict(zip(features, my_linear_model.coef_))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iQ71UGbaUjQp"
      },
      "outputs": [],
      "source": [
        "# Let's get some predictions from the model\n",
        "preds = my_linear_model.predict(cleaned_df[features])\n",
        "predictions_df = cleaned_df.assign(predicted_mpg=preds)\n",
        "predictions_df[[\"mpg\", \"predicted_mpg\"]].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qipNNfNYUjQu"
      },
      "outputs": [],
      "source": [
        "# Can we visualize how good our predictions are?\n",
        "# Let's plot the predicted mpg vs. the true value\n",
        "predictions_df.plot(kind=\"scatter\", x=\"mpg\", y=\"predicted_mpg\")\n",
        "# Q: What would perfect predictions look like?\n",
        "# Q: How would you assess our predictive ability here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfwBsUu5UjQ0"
      },
      "source": [
        "##*Hands-on exercises -- on your own*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRV7ZnsyUjQ2"
      },
      "source": [
        "To master your new-found knowledge of Python, try these hands-on examples. \n",
        "\n",
        "Your next homework will be in a similar format to this section.\n",
        "\n",
        "Consider the following URL to a CSV file containing the results of compressive tests for various types of concrete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "33kJi31dUjQ2"
      },
      "outputs": [],
      "source": [
        "concrete_url = \"https://www.openml.org/data/get_csv/1762521/phpZGl7F2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWB2fSMvUjQ8"
      },
      "source": [
        "**1. Load the CSV data into a pandas data frame. Print some high-level statistical info about the data frame's columns. HINT: You may also want to rename the columns.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PnfHFM7vUjQ9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdEKd37rUjRD"
      },
      "source": [
        "**2. How many rows have a compressive strength > 40 MPa?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wAPo_MyoUjRF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE_Pou3mUjRL"
      },
      "source": [
        "**3. Plot the histogram of Coarse Aggregate and Fine Aggregate values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "joN56kLhUjRM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ80EX7CUjRQ"
      },
      "source": [
        "**4. Make a plot comparing compressive strength to age**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ym9pm-ffUjRS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji4nopGnUjRX"
      },
      "source": [
        "**5. Make a plot comparing compressive strength to age for only those rows with < 750 fine aggregate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5lELzHgTUjRY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Vav_5KUjRd"
      },
      "source": [
        "**6. Try to build a linear model that predicts compressive strength given the other available fields**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_Vs1mpUHUjRf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcds0j-3UjRi"
      },
      "source": [
        "**7. Generate predictions for all the observations and a scatterplot comparing the predicted compressive strengths to the actual values.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gu92GthtUjRk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Dealing_with_data.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}